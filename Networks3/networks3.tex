\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{float} % Allows use of [H] float option
\usepackage{amsfonts} % For \mathbb
\usepackage{amsmath}

\title{Networks 3}
\author{Haim Lavi, 038712105}
\date{December 2025}

\begin{document}

\maketitle

\section{}
Code is in https://github.com/HaimL76/Networks.git
\section{}
All the plots in this section are for the BA model without fitness.
\subsection{}
Graph of the average degree as function of the time / number of nodes. We get almost immediately $\langle{k}\rangle=2m$, except for $t=0$ where $\langle{k}\rangle=m-1$.
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.85\linewidth]{ba_model_k_average_n.png}
    }
\end{figure}
\subsection{}
Graph of the degree ratio as function of the square root of the time / number of nodes.
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.75\linewidth]{ba_model_k_ratio_n.png}
}
\end{figure}
\subsection{}
Graph of the degree of several nodes as function of the time / number of nodes (in log-log scale).
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.75\linewidth]{ba_model_ki_t_loglog.png}
    }
\end{figure}
\subsection{}
Graph of the degree distribution (in log-log scale, with the calculated distribution). Notice that since our network is finite, then $\mathbb{P}[k]$ is either zero or $\geq\frac{1}{N}$ (either no node has this $k$, or at least one does), so taking only degrees that appear in the graph, we get the line of $\mathbb{P}[k]$ to turn away from the calculated slope and fix around $\frac{1}{N}$, for the highest degrees.
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.75\linewidth]{ba_model_p_k_loglog_with_slope.png}
    }
\end{figure}
Graph of the degree distribution (in log-log scale, with log binning, with the calculated distribution). We need to divide the density of each bin in the total sum of degrees, to get the log binning close enough to the calculated degree distribution.
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.75\linewidth]{ba_model_p_k_loglog_binning_with_slope.png}
    }
\end{figure}
Graph of the degree distribution (in log-log scale, with log binning taking medians only, with the calculated distribution).
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.75\linewidth]{ba_model_p_k_loglog_binning_with_slope_take_medians.png}
    }
\end{figure}
\section{}
We use the same analysis method, $\frac{dk_i}{dt}(t)=m\pi_i(t)=m\frac{k_i\eta_i}{\sum_{j=1}^tk_j\eta_j}$, where $\eta_i$ is fixed for every node $i$ (the node that appears at $t=i$). Taking $\eta_i=\alpha$ for all $i$, where $\alpha$ is some constant, reduces to the BA preferential attachment model. Taking $\eta_i>\eta_j$ for every $i<j$ only increases the early comers advantage in this model, because then $\pi_i>>\pi_j$, so $\eta_i$ cannot be a valid fitness. So we must take $\eta_j>\eta_i$ for every $i<j$. But in order to have the fitter nodes match or surpass the early comers, we need $\pi_1\leq\pi_2\leq\cdots\leq\pi_N$.
Schematically, it is sufficient that $\frac{dk_j}{dt}(t=j)>\frac{dk_i}{dt}(t=j)\iff{\pi_j}(t=j)>\pi_i(t=j)\iff{\eta_j}>\eta_i\frac{k_i}{k_j}(t=j)$ for $i<<j$, but $\frac{k_i}{k_j}(t=j)=\frac{k_i(t=j)}{m}>>1\implies{\eta_j}>>\eta_i$. This means that if the slope for node $j$ is higher than the slope for node $i$, then the line for $\log(\frac{k_j}{m})$ will have an intersection point with $\log(\frac{k_i}{m})$ at some point, and will surpass it thereafter. So in infinite networks this always happens, but in a finite network (like our numeric simulation), there are always late comers that have lower degrees than early comers, because for every node $i$ and every time $t$, $\frac{dk_i}{dt}(t)\leq{m}$ (meaning the growth in time is bounded by $m$), so if $k_i>N-j$, node $j$ will not have enough steps to gain a large enough degree to match node $i$ before the attachment process ends, even if $\frac{dk_j}{dt}$ is close enough to $m$.
I found the general analysis complicated, so I will try to demonstrate this with an example.
First, we take a hypothetic network where all the nodes have $\eta_i=1$, and a particular node $s$ (appearing at $t=s)$ has $\eta_s=\alpha$, for some large constant $\alpha>>1$. For this network, $\frac{dk_i}{dt}=m\pi_i=m\frac{\pi_i}{\sum}$ for every $i\neq{s}$, and $\frac{dk_s}{dt}=m\pi_s=m\frac{k_s\eta_s}{\sum}>>m\pi_i$. So $\mathbb{P}[k_s(t+1)=m+1|k_S(t)=m]$ is close to $1$, while the other new links are uniformly distributed between the other nodes, so at any time $t>>s$, $\mathbb{E}[k_s(t)]\approx{t-s}$ (because on every step, node $s$ almost surely receives a new link), while $\mathbb{E}[k_i(t)]$ behaves approximately by the classic preferential attachment model, that is $\frac{k_i}{m}\approx\sqrt{\frac{t}{t_i}}$, so $\sqrt{\frac{t}{t_i}}\approx{t-s}\implies\frac{t}{t_i}\approx{t^2}-2st+s^2\implies{t^2-(2s+\frac{1}{t_i})t+s^2}\approx{0}$, but $s$ and $t_i$ are constants, and $t^2>>t$ for a large enough $t$, so there always exists some $t'$ where this equation holds for every $t>t'$. But since $t^2>>t$, and $s$ and $t_i$ are constants, then for $t>>s>t_i$, we neglect the two constants and have $t>>\sqrt{t}$, which means that $\mathbb{E}[k_s(t)]>>\mathbb{E}[k_i(t)]$. For a more reasonable fitness distribution, the analysis is more complicated. We can consider non-linear growth (that is non-linear log-log of growth), for instance, we can take $\eta_i=i$ or $\eta_i=2^i$ (Which are also not very realistic), and show that $\pi_j(t+1)-\pi_i(t+1)\geq\pi_j(t)-\pi_i(t)$ for every $i<j$ and every time $t$, so eventually $\mathbb{E}[k_j(t)]>>\mathbb{E}[k_i(t)]$. 
\newpage
Graph of $K_i(t)$, for several nodes $i$, where $\eta_i=i$
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.75\linewidth]{ba_model_ki_t_loglog_fitness_linear.png}
    }
\end{figure}
\newpage
Graph of $K_i(t)$, for several nodes $i$, where $\eta_i=2^i$
\begin{figure}[H]
    \makebox[\linewidth]{
\includegraphics[width=1.75\linewidth]{ba_model_ki_t_loglog_fitness_square.png}
    }
\end{figure}
\end{document}
